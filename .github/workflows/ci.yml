name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHONUNBUFFERED: "1"
  FORCE_COLOR: "1"
  # Optional filter for e2e tests; when set, CI will not fail
  # if no tests match (pytest exit code 5).
  PYTEST_E2E_K: ""

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies (pinned to pre-commit versions)
        run: |
          python -m pip install --upgrade pip
          pip install \
            black==23.7.0 \
            ruff==0.4.0 \
            isort==5.12.0 \
            mypy==1.4.1
          
      - name: Run Black
        run: black --check --diff zeroproof
        
      - name: Run Ruff
        run: ruff check zeroproof
        
      - name: Run isort
        run: isort --check-only --diff zeroproof
        
      - name: Run MyPy (public surface)
        run: mypy

      - name: Run MyPy on examples (informational)
        run: mypy examples || true

  test:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.10', '3.11', '3.12', '3.13']
            
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-test-${{ matrix.python-version }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-test-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-test-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
          
      - name: Run unit tests
        run: pytest tests/unit -v --tb=short
        
      - name: Run property tests
        run: pytest tests/property -v --tb=short -m property
        
      - name: Run integration tests (guard no-match)
        shell: bash
        run: |
          set +e
          KOPT=""
          if [ -n "${PYTEST_E2E_K:-}" ]; then
            echo "Using pytest -k filter: ${PYTEST_E2E_K}"
            KOPT="-k ${PYTEST_E2E_K}"
          fi
          pytest tests/e2e -v --tb=short -m "not slow" $KOPT
          ec=$?
          set -e
          if [ "$ec" -eq 5 ] && [ -n "${PYTEST_E2E_K:-}" ]; then
            echo "No tests matched -k '${PYTEST_E2E_K}' — skipping."
            exit 0
          fi
          exit "$ec"

  test-frameworks:
    name: Test Framework Integration - ${{ matrix.framework }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        framework: [torch, jax]
        
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.framework }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.framework }}-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[${{ matrix.framework }},dev]
          
      - name: Run framework tests (exclude heavy integration)
        run: pytest tests -v --tb=short -k ${{ matrix.framework }} --ignore=tests/integration --ignore=tests/e2e

  coverage:
    name: Coverage
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-coverage-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-coverage-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[all,dev]
          
      - name: Run tests with coverage
        run: |
          pytest --cov=zeroproof --cov-report=xml --cov-report=html --cov-report=term-missing
          
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  import-smoke:
    name: Import Smoke Test (minimal deps)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install package (no extras)
        run: |
          python -m pip install --upgrade pip
          pip install -e .
      - name: Import zeroproof
        run: python -c "import zeroproof; print(zeroproof.__version__)"

  license-headers:
    name: License Header Check (non-blocking)
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Run license header checker
        run: |
          python - <<'PY'
          import sys, pathlib
          ROOT = pathlib.Path('zeroproof')
          missing = []
          for p in ROOT.rglob('*.py'):
              text = p.read_text(encoding='utf-8', errors='ignore')
              head = '\n'.join(text.splitlines()[:5])
              if 'MIT License' not in head and 'OSI Approved :: MIT' not in text:
                  missing.append(str(p))
          if missing:
              print('Files missing MIT license header (count=%d):' % len(missing))
              for f in missing[:50]:
                  # Emit as GitHub Actions warnings instead of failing the step
                  print(f"::warning::Missing MIT license header: {f}")
              # Do not fail the step in non-blocking mode
              pass
          PY

  property-suite:
    name: Property Test Suite
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-property-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-property-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
          
      - name: Run extensive property tests
        run: |
          pytest tests/property -v --hypothesis-profile=ci -m property

  no-nan-guarantee:
    name: No-NaN E2E Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-e2e-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-e2e-
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[all,dev]
          
      - name: Run No-NaN guarantee tests (guard no-match)
        shell: bash
        run: |
          set +e
          pytest tests/e2e -v -k "no_nan" --tb=short
          ec=$?
          set -e
          if [ "$ec" -eq 5 ]; then
            echo "No tests matched -k 'no_nan' — skipping."
            exit 0
          fi
          exit "$ec"

  benchmarks:
    name: Benchmarks (mini suite)
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
      - name: Run mini benchmark suite
        run: |
          python -m zeroproof.bench --suite all --out benchmark_results --iterations 300 --samples 3
          python -m zeroproof.overhead_cli --out benchmark_results/overhead.json
      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        with:
          name: mini-benchmarks
          if-no-files-found: ignore
          path: |
            benchmark_results/*.json
            benchmark_results/summary.txt
      - name: Compare against baseline (if present)
        run: |
          if [ -f benchmarks/baseline.json ]; then \
            python -m zeroproof.bench_compare \
              --baseline benchmarks/baseline.json \
              --candidate $(ls -1 benchmark_results/*.json | tail -n1) \
              --max-slowdown 1.20 ; \
          else \
            echo "No baseline found at benchmarks/baseline.json; skipping compare." ; \
          fi

  determinism-safety:
    name: Determinism & Safety
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies (dev)
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
      - name: Run determinism tests (policy/tagging)
        run: |
          pytest -v --tb=short \
            tests/unit/test_tr_policy_tagging.py \
            tests/unit/test_tr_properties.py::TestDeterminism \
            tests/unit/test_deterministic_reductions_toggle.py
      - name: Seed-fixed mini-training loop
        run: |
          python - <<'PY'
          import math
          import zeroproof as zp

          def build_data(center=0.5, exclude=0.05):
              xs = [-1.0, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
              xs = [x for x in xs if abs(x - center) >= exclude]
              def f(x):
                  return 1.0/(x - center)
              batch = ([zp.real(float(x)) for x in xs], [zp.real(float(f(x))) for x in xs])
              return [batch]

          def run_once():
              # Deterministic reductions on
              zp.TRPolicyConfig.set_policy(zp.TRPolicy(deterministic_reduction=True))
              basis = zp.layers.ChebyshevBasis()
              model = zp.layers.TRRational(d_p=2, d_q=1, basis=basis, alpha_phi=1e-3)
              cfg = zp.training.TrainingConfig(learning_rate=0.01, max_epochs=5, use_adaptive_loss=False, verbose=False)
              trainer = zp.training.TRTrainer(model, config=cfg)
              data = build_data()
              hist = trainer.train(data, data)
              # Evaluate tags on the same data deterministically
              y_tags = []
              for (inputs, _) in data:
                  for x in inputs:
                      y, tag = model.forward(x)
                      y_tags.append(tag)
              counts = {
                  'REAL': sum(1 for t in y_tags if t == zp.TRTag.REAL),
                  'PINF': sum(1 for t in y_tags if t == zp.TRTag.PINF),
                  'NINF': sum(1 for t in y_tags if t == zp.TRTag.NINF),
                  'PHI':  sum(1 for t in y_tags if t == zp.TRTag.PHI),
              }
              return hist['loss'][-1], counts

          loss1, c1 = run_once()
          loss2, c2 = run_once()
          print('loss1', loss1, 'loss2', loss2, 'counts1', c1, 'counts2', c2)
          assert not (math.isnan(loss1) or math.isnan(loss2))
          assert abs(loss1 - loss2) < 1e-12
          assert c1 == c2
          PY

  
